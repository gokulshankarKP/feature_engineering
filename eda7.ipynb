{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EKtGweuGQtl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Imbalanced Dataset with Machine Learning"
      ],
      "metadata": {
        "id": "mysUkMnY47FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('creditcard.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "50AeO4ZF471j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "tXJaZi_A4-AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "id": "y1_6oevD4-Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Independent and Dependent Features\n",
        "X=df.drop(\"Class\",axis=1)\n",
        "y=df.Class"
      ],
      "metadata": {
        "id": "jcwkENxt4-FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Validation Like KFOLD and Hyperpaqrameter Tuning"
      ],
      "metadata": {
        "id": "Egu9ASdd5Ecx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "7_lmeFEg4-H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10.0 **np.arange(-2,3)\n"
      ],
      "metadata": {
        "id": "yhJpCzix4-Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_class=LogisticRegression()\n",
        "grid={'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
        "cv=KFold(n_splits=5,random_state=None,shuffle=False)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)\n",
        "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')\n",
        "clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "v-YRRI3S4-NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Ry4N75yZ4-Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "347*100"
      ],
      "metadata": {
        "id": "L6XigclN4-SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EW_QjaRX5fgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "-2lKT6Le4-U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight=dict({0:1,1:100})"
      ],
      "metadata": {
        "id": "L_UZitHR5RlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier(class_weight=class_weight)\n",
        "classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "ghcnead55Rny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "bSHID_V-5RrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rv2r7R8L5ZZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under Sampling"
      ],
      "metadata": {
        "id": "Q8uvsqsP5gbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(y_train)"
      ],
      "metadata": {
        "id": "vw7RkfrC5Zca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.under_sampling import NearMiss\n",
        "ns=NearMiss(0.8)\n",
        "X_train_ns,y_train_ns=ns.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "metadata": {
        "id": "CRgEOsCo5hpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "metadata": {
        "id": "SyXhLUCI5ZfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "1VCpjKEm5Zh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRGmCYAU5ZlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over Sampling"
      ],
      "metadata": {
        "id": "QwYZPRy25rF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "os=RandomOverSampler(0.75)\n",
        "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "metadata": {
        "id": "avBAiQxx5stc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "metadata": {
        "id": "KKOW3mRz5tc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "8GB2a7Zq5tfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTETomek"
      ],
      "metadata": {
        "id": "pToYZ13A50nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "os=SMOTETomek(0.75)\n",
        "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "metadata": {
        "id": "DiHXmo-c5tiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "classifier.fit(X_train_ns,y_train_ns)"
      ],
      "metadata": {
        "id": "AYOMAwZO5tl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "pZKua-sn56LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Techniques"
      ],
      "metadata": {
        "id": "KOxQ4Q0t57w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "easy=EasyEnsembleClassifier()\n",
        "easy.(X_train,y_train)"
      ],
      "metadata": {
        "id": "sEVR8VaO56Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "easy.\n",
        "y_pred=easy.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "cU68SQHa56QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "over sampling imbalaced"
      ],
      "metadata": {
        "id": "DjPzzUey6Kuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detection-5 and the page of the DefeatFraud project\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "LABELS = [\"Normal\", \"Fraud\"]\n",
        "data = pd.read_csv('creditcard.csv',sep=',')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "S5UTDIww56Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "YdZ0W2IH6VEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create independent and Dependent Features\n",
        "columns = data.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Class\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Class\"\n",
        "# Define a random state\n",
        "state = np.random.RandomState(42)\n",
        "X = data[columns]\n",
        "Y = data[target]\n",
        "# Print the shapes of X & Y\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "32ogoZPy6VHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "kjWEuSy_6fPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().values.any()"
      ],
      "metadata": {
        "id": "F35oadZ36VK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count_classes = pd.value_counts(data['Class'], sort = True)\n",
        "\n",
        "count_classes.plot(kind = 'bar', rot=0)\n",
        "\n",
        "plt.title(\"Transaction Class Distribution\")\n",
        "\n",
        "plt.xticks(range(2), LABELS)\n",
        "\n",
        "plt.xlabel(\"Class\")\n",
        "\n",
        "plt.ylabel(\"Frequency\")\n"
      ],
      "metadata": {
        "id": "Khqk4GoL6V4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the Fraud and the normal dataset\n",
        "\n",
        "fraud = data[data['Class']==1]\n",
        "\n",
        "normal = data[data['Class']==0]\n",
        "print(fraud.shape,normal.shape)"
      ],
      "metadata": {
        "id": "LPjwtQkS6V7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import NearMiss\n",
        "# Implementing Oversampling for Handling Imbalanced\n",
        "smk = SMOTETomek(random_state=42)\n",
        "X_res,y_res=smk.fit_sample(X,Y)\n",
        "X_res.shape,y_res.shape"
      ],
      "metadata": {
        "id": "iIaLIw1T6V98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print('Original dataset shape {}'.format(Counter(Y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_res)))"
      ],
      "metadata": {
        "id": "CzJgEdB46WBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RandomOverSampler to handle imbalanced data\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "os =  RandomOverSampler(ratio=0.5)\n",
        "X_train_res, y_train_res = os.fit_sample(X, Y)\n",
        "X_train_res.shape,y_train_res.shape\n"
      ],
      "metadata": {
        "id": "otVPIZp06Wnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original dataset shape {}'.format(Counter(Y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_train_res)))"
      ],
      "metadata": {
        "id": "YCjPMuGU6WqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example I use SMOTETomek which is a method of imblearn. SMOTETomek is a hybrid method\n",
        "# which uses an under sampling method (Tomek) in with an over sampling method (SMOTE).\n",
        "os_us = SMOTETomek(ratio=0.5)\n",
        "\n",
        "X_train_res1, y_train_res1 = os_us.fit_sample(X, Y)\n",
        "X_train_res1.shape,y_train_res1.shape"
      ],
      "metadata": {
        "id": "e8qZ2SkO6Ws3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original dataset shape {}'.format(Counter(Y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_train_res1)))"
      ],
      "metadata": {
        "id": "fsjIy15n6Wvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J16bRQuY6Wx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "under sampling"
      ],
      "metadata": {
        "id": "Z5S4rHOY7BYt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DCZakWKD7D9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xTSI7aJf7Enn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit Card Kaggle- Handle Imbalanced Dataset\n",
        "Context\n",
        "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
        "\n",
        "Content\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
        "\n",
        "Inspiration\n",
        "Identify fraudulent credit card transactions.\n",
        "\n",
        "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
        "\n",
        "Acknowledgements\n",
        "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the DefeatFraud project"
      ],
      "metadata": {
        "id": "GcPzM8Ch7Eug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.svm import OneClassSVM\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "LABELS = [\"Normal\", \"Fraud\"]\n",
        "data = pd.read_csv('creditcard.csv',sep=',')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "gdTwMf9D7J2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "evIsaGqM7NvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create independent and Dependent Features\n",
        "columns = data.columns.tolist()\n",
        "# Filter the columns to remove data we do not want\n",
        "columns = [c for c in columns if c not in [\"Class\"]]\n",
        "# Store the variable we are predicting\n",
        "target = \"Class\"\n",
        "# Define a random state\n",
        "state = np.random.RandomState(42)\n",
        "X = data[columns]\n",
        "Y = data[target]\n",
        "X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n",
        "# Print the shapes of X & Y\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "uUUKoY1x7Nxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "TsXTaBsO7S0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().values.any()\n",
        "\n",
        "count_classes = pd.value_counts(data['Class'], sort = True)\n",
        "\n",
        "count_classes.plot(kind = 'bar', rot=0)\n",
        "\n",
        "plt.title(\"Transaction Class Distribution\")\n",
        "\n",
        "plt.xticks(range(2), LABELS)\n",
        "\n",
        "plt.xlabel(\"Class\")\n",
        "\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "hZxuVe1-7N0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the Fraud and the normal dataset\n",
        "\n",
        "fraud = data[data['Class']==1]\n",
        "\n",
        "normal = data[data['Class']==0]\n",
        "print(fraud.shape,normal.shape)"
      ],
      "metadata": {
        "id": "tmgC4KMd7N31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "# Implementing Undersampling for Handling Imbalanced\n",
        "nm = NearMiss(random_state=42)\n",
        "X_res,y_res=nm.fit_sample(X,Y)"
      ],
      "metadata": {
        "id": "YNIQ8QYm7aap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_res.shape,y_res.shape"
      ],
      "metadata": {
        "id": "UnoQC40w7adk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print('Original dataset shape {}'.format(Counter(Y)))\n",
        "print('Resampled dataset shape {}'.format(Counter(y_res)))"
      ],
      "metadata": {
        "id": "W2Bs8sqn7age"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CeZSNh0T7ajl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gknbbmP87OFd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}